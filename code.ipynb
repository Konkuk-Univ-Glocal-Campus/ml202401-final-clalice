{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모듈 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.10/site-packages (1.5.0)\n",
      "Requirement already satisfied: nltk in /usr/local/python/3.10.13/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: matplotlib in /home/codespace/.local/lib/python3.10/site-packages (3.9.0)\n",
      "Requirement already satisfied: seaborn in /home/codespace/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: click in /usr/local/python/3.10.13/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (4.52.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn nltk matplotlib seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('vader_lexicon', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 호출 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to preprocessed_wine_reviews.csv\n",
      "Preprocessed data with sentiment saved to preprocessed_wine_reviews_with_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('wine_review.csv')\n",
    "\n",
    "# 필요한 열 선택\n",
    "df = df[['name', 'reviews.rating', 'reviews.text']]\n",
    "\n",
    "# 결측값 제거\n",
    "df = df.dropna()\n",
    "\n",
    "# NLTK 불용어 다운로드\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# NLTK 불용어 설정\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# 텍스트 전처리 함수 정의\n",
    "def preprocess_text(text):\n",
    "    # 소문자 변환\n",
    "    text = text.lower()\n",
    "    # 특수 문자 제거\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # 토큰화\n",
    "    tokens = word_tokenize(text)\n",
    "    # 불용어 제거\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    # 표제어 추출\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    # 리스트를 공백으로 결합하여 문자열로 반환\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# 리뷰 텍스트 전처리\n",
    "df['cleaned_text'] = df['reviews.text'].apply(preprocess_text)\n",
    "\n",
    "# 필요한 열 선택\n",
    "df = df[['name', 'reviews.rating', 'cleaned_text']]\n",
    "\n",
    "# 전처리된 데이터를 CSV 파일로 저장\n",
    "output_filename = 'preprocessed_wine_reviews.csv'\n",
    "df.to_csv(output_filename, index=False)\n",
    "print(f\"Preprocessed data saved to {output_filename}\")\n",
    "\n",
    "# 감정 분석기 초기화\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# 감정 분석 함수 정의\n",
    "def analyze_sentiment(text):\n",
    "    # NaN 값이면 중립(0)으로 반환\n",
    "    if isinstance(text, float) and np.isnan(text):\n",
    "        return 0\n",
    "    \n",
    "    # 감정 분석 수행\n",
    "    sentiment_score = sid.polarity_scores(text)\n",
    "    if sentiment_score['compound'] >= 0.05:\n",
    "        return 1  # Positive\n",
    "    elif sentiment_score['compound'] <= -0.05:\n",
    "        return -1  # Negative\n",
    "    else:\n",
    "        return 0  # Neutral\n",
    "\n",
    "# 전처리된 데이터 불러오기\n",
    "df = pd.read_csv('preprocessed_wine_reviews.csv')\n",
    "\n",
    "# NaN 값이 있는 행 제거\n",
    "df = df.dropna(subset=['cleaned_text'])\n",
    "\n",
    "# 'cleaned_text' 열에 대해 감정 분석을 수행하여 'sentiment' 열 추가\n",
    "df['sentiment'] = df['cleaned_text'].apply(analyze_sentiment)\n",
    "\n",
    "# 필요한 열 선택\n",
    "df = df[['name', 'cleaned_text', 'reviews.rating', 'sentiment']]\n",
    "\n",
    "# 전처리된 데이터를 CSV 파일로 저장\n",
    "output_sentiment_filename = 'preprocessed_wine_reviews_with_sentiment.csv'\n",
    "df.to_csv(output_sentiment_filename, index=False)\n",
    "print(f\"Preprocessed data with sentiment saved to {output_sentiment_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리한 데이터셋 컬럼확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'cleaned_text', 'reviews.rating', 'sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 'processed_wine_reviews.csv' 파일을 로드\n",
    "#df = pd.read_csv('preprocessed_wine_reviews.csv')\n",
    "df = pd.read_csv('preprocessed_wine_reviews_with_sentiment.csv')\n",
    "# 데이터프레임의 컬럼 확인\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best parameters found: {'svm__C': 10, 'svm__kernel': 'rbf', 'tfidf__max_features': 3000, 'tfidf__ngram_range': (1, 1)}\n",
      "Cross-validation scores: [0.85421995 0.84654731 0.85933504 0.83887468 0.85384615]\n",
      "Mean accuracy: 0.8505646271886681\n",
      "Test accuracy: 0.8548057259713702\n",
      "Best model saved to wine_review_sentiment_svm_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 전처리된 데이터 불러오기\n",
    "df = pd.read_csv('preprocessed_wine_reviews_with_sentiment.csv')\n",
    "# 특성과 타겟 설정\n",
    "X = df['cleaned_text']\n",
    "y = df['sentiment']\n",
    "\n",
    "# 학습 세트와 테스트 세트로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# TF-IDF 벡터화와 SVM 모델을 파이프라인으로 구성\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svm', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [1000, 2000, 3000, None],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'svm__C': [0.1, 1, 10, 100],\n",
    "    'svm__kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# 그리드 서치를 사용하여 모델 튜닝\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "# 교차 검증을 통해 모델 평가\n",
    "cv_results = cross_val_score(grid_search.best_estimator_, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation scores:\", cv_results)\n",
    "print(\"Mean accuracy:\", cv_results.mean())\n",
    "# 테스트 세트로 최종 평가\n",
    "test_accuracy = grid_search.best_estimator_.score(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "import joblib\n",
    "\n",
    "# 최적의 모델을 저장\n",
    "model_filename = 'wine_review_sentiment_svm_model.pkl'\n",
    "joblib.dump(grid_search.best_estimator_, model_filename)\n",
    "print(f\"Best model saved to {model_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
